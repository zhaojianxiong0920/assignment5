{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "“Assignment 5 - NN_from_scratch_MNIST.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [
        "wwjbskARV-Vk"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZRq-IGV-Td",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5 - Neural Networks Implementation (due: Wed April 15th)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NydV8iKpV-Te",
        "colab_type": "text"
      },
      "source": [
        "This notebook show neural networks implemnetation on the MNIST hand-written dataset.  Adapted from a version published by https://github.com/jdwittenauer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJRFUJwFV-Tf",
        "colab_type": "text"
      },
      "source": [
        "We are going go over the neural network architecture discussed in class. This includes the feed-forward neural network - from input through the hidden layers to the out put and adjusting the weights as to minimize the loss step-by-step through each layer called **backpropagation.**  We'll implement both unregularized and regularized versions of the neural network cost function and gradient computation in the backpropagation function.  We'll also implement random weight initialization and a method to use the network to make predictions.\n",
        "\n",
        "Instead of manually going through gradient descent iterations, we'll simply use a package available for minimizing the backpropogation function.\n",
        "\n",
        "The MNIST data set is available in different sizes and formats from different sources.  We will use the one made avialble here: \"ex3data1.mat\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svU5lMvYV-Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeuuSgXXV-Tk",
        "colab_type": "text"
      },
      "source": [
        "The data we are loading is a dictionary that contains both input data and output.  The input data is a 2D numpy array X contains 5000 grayscale images of handwritten digits of 0, 1, 2, 3, ... 9.  Each raw of 400 entries between 0 and 255 that are grayscale intensity values of 20X20 pixel representation of a handwritten digit that is unrolled into a single vector.\n",
        "\n",
        "The output y contains the corresponding labels of 0,1,2, ..., 9.  \n",
        "\n",
        "Note that in the original convention followed for this dataset: 0 is mapped to 10, while all other labels are exactly the digit they represent.  Unlike in many other programming languages Python entries start at 0 and so we will change 10 back to 0 as it ought to be.\n",
        "\n",
        "**Multiclass classification:** You may notice that in our logistic regression models the output could only be one of two values: 0 or 1.  However what we are attempting here is an example of multiclass classification: outputs of more than two values - 10 in this case.  Neural networks facilitates this easily. In fact what we will allow now is the terminal layer to consist of multiple activations: 10 in this problem.  We use a function called softmax to make the outputs to be probabilties that adds upto 1.  The predicted value will correspond to the activation node with highest probabilty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUEkJtltWJVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5hGKeQKWKIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "28aa014f-cb6e-4108-9f2d-6f760c280a1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLKSQffRV-Tl",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #1: \n",
        "\n",
        "Load the data following the following five cells or by running the 6th cell\n",
        "\n",
        "- you should have the X and y from data in the dataframes X_df and y_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQCvnRGKV-Tm",
        "colab_type": "code",
        "outputId": "d772d747-50cb-449a-9830-cc2d7d0a9a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "##This is a dictionary that contains both input data and output.\n",
        "data = loadmat('/content/drive/My Drive/MATH3790Sec1/assign5/ex3data1.mat')\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " '__globals__': [],\n",
              " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
              " '__version__': '1.0',\n",
              " 'y': array([[10],\n",
              "        [10],\n",
              "        [10],\n",
              "        ...,\n",
              "        [ 9],\n",
              "        [ 9],\n",
              "        [ 9]], dtype=uint8)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMoN8kEnV-Ts",
        "colab_type": "code",
        "outputId": "b8a5948e-66d2-42df-a1df-c785787f060c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data['X'].shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq8vKz9OV-Ty",
        "colab_type": "text"
      },
      "source": [
        "This is the data we will be using through out, let's create some useful variables up-front."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whjhd_FAV-Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data['X']\n",
        "y = data['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNK4DAZcV-T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let us set the values '10' back what it ought to be: 0\n",
        "y[y==10]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRdQF-IiV-T8",
        "colab_type": "text"
      },
      "source": [
        "#### Let us convert these data sets into dataframes so we can pickle them and move them around without losing integrity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-13H5adSV-T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaaJ-rhIV-UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "X_df = pd.read_pickle('/content/drive/My Drive/MATH3790Sec1/assign5/X_df.pkl')\n",
        "y_df = pd.read_pickle('/content/drive/My Drive/MATH3790Sec1/assign5/y_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMF7tSJLV-UG",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #2:\n",
        "\n",
        "Display **20** randomly selected images from X_df and display them in two rows by appropriately changing the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-ggZG4SV-UH",
        "colab_type": "code",
        "outputId": "c9601da1-566c-402b-8132-97b3ac193d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#Let us quickly checkout what is in these data sets:\n",
        "sample = np.random.randint(0,len(X), 20)\n",
        "X_samples = [X[i,:] for i in sample]\n",
        "\n",
        "#plot the digits\n",
        "i = 0\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=10)\n",
        "for row in ax:\n",
        "    for col in row:\n",
        "        col.imshow(X_samples[i].reshape(20,20))\n",
        "        i += 1\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r3yx9jIV-UM",
        "colab_type": "code",
        "outputId": "5c2259a9-c179-4438-b1e1-0799f858249f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#Checkout their labels\n",
        "y[sample].flatten()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 4, 5, 6, 7, 8, 3, 0, 1, 9, 9, 4, 8, 7, 6, 8, 8, 8, 3, 2],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6YbA0LV-UQ",
        "colab_type": "text"
      },
      "source": [
        "**One hot encoding:** Now we need to turn the label array into what is called one-hot-encoded matrix.  The one-hot-matrix is a representation of representation of a n-dimensional vector of values 0, 1, 2, ..., 9 as in here into 10Xn matrix where each column will have all zeros except exactly one 1 in the position corresponding to the value the column represents.  For example 7 will be a column where all entries except the 7th are all zeros and the 7th is a one.\n",
        "\n",
        "One-hot-encoding is a way to represent a vector with binary entries alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Twf1PfV-UR",
        "colab_type": "code",
        "outputId": "d0e30f74-2e0f-4660-b96a-755c10d75219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = encoder.fit_transform(y)\n",
        "y_onehot.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sGzpNxEV-UX",
        "colab_type": "code",
        "outputId": "cc6a04ce-2101-4395-a509-1ccd63ffce88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Here is an example of an y entry and its one-hot-encoding\n",
        "y[0], y_onehot[0,:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0], dtype=uint8), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M6Erkn_V-Ud",
        "colab_type": "text"
      },
      "source": [
        "The neural network we're going to build for this exercise has an input layer matching the size of our instance data (400 + the bias unit), a hidden layer with 25 units (26 with the bias unit), and an output layer with 10 units corresponding to our one-hot encoding for the class labels. \n",
        "\n",
        "The first piece we need to implement is a cost function to evaluate the loss for a given set of network parameters.  The source mathematical function is in the exercise text (and looks pretty intimidating).  Here are the functions required to compute the cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9POtj5jV-Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCVVJzumV-Uh",
        "colab_type": "text"
      },
      "source": [
        "## Forward propogation and Cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKTZ6ZEiV-Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Forward propogation: This takes us through one sweep from input through one hidden layer to the outputs\n",
        "def forward_propagate(X, theta1, theta2):\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    #First insert a a row of ones into the X data - 0th column\n",
        "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
        "    \n",
        "    #Caluculate the X*Theta\n",
        "    z2 = a1 * theta1.T\n",
        "    \n",
        "    #now apply the sigmoid function and then insert a column of ones\n",
        "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
        "    \n",
        "    #Calculate X*Theta\n",
        "    z3 = a2 * theta2.T\n",
        "    \n",
        "    #The outputs\n",
        "    h = sigmoid(z3)\n",
        "    \n",
        "    #Now return all the calculates values that we need for calculating and then backpropagation\n",
        "    return a1, z2, a2, z3, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soE_b1YTV-Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cost\n",
        "def cost(params, input_size, hidden_size1, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    n1 = hidden_size1 * (input_size + 1)\n",
        "    n2 = n1 + num_labels * (hidden_size1 + 1)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:n1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[n1:n2], (num_labels, (hidden_size1 + 1))))\n",
        "\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = - np.multiply(y[i,:], np.log(h[i,:]))\n",
        "        second_term = - (np.multiply((1 - y[i,:]), np.log(1 - h[i,:])))\n",
        "        J += np.sum(first_term + second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uegmgkUV-Uq",
        "colab_type": "text"
      },
      "source": [
        "We've used the sigmoid function before so that's not new.  The forward-propagate function computes the hypothesis for each training instance given the current parameters.  It's output shape should match the same of our one-hot encoding for y.  We can test this real quick to convince ourselves that it's working as expected (the intermediate steps are also returned as these will be useful later)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frW7ZPXHV-Ur",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #3\n",
        "\n",
        "Work the rest of this application (except for exercise 4 later) using hidden_size2 set to 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvRoacI6V-Ur",
        "colab_type": "code",
        "outputId": "278eee4b-2bac-43cc-abae-966998df148d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# initial setup\n",
        "input_size = 400\n",
        "hidden_size2 = 50\n",
        "num_labels = 10\n",
        "learning_rate = 1\n",
        "\n",
        "# randomly initialize a parameter array of the size of the full network's parameters\n",
        "params = (np.random.random(size=hidden_size2 * (input_size + 1) + num_labels * (hidden_size2 + 1)) - 0.5) * 0.25\n",
        "\n",
        "m = X.shape[0]\n",
        "X = np.matrix(X)\n",
        "y = np.matrix(y)\n",
        "\n",
        "# unravel the parameter array into parameter matrices for each layer\n",
        "theta1 = np.matrix(np.reshape(params[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(params[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "theta1.shape, theta2.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50, 401), (10, 51))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpxmOBIyV-Uw",
        "colab_type": "code",
        "outputId": "c0fa7161-a0a3-4faa-aaec-d21da3bd0241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 401), (5000, 50), (5000, 51), (5000, 10), (5000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfLuXFMPV-U0",
        "colab_type": "text"
      },
      "source": [
        "The cost function, after computing the hypothesis matrix h, applies the cost equation to compute the total error between y and h."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62upkVuNV-U0",
        "colab_type": "code",
        "outputId": "5d0b270a-5474-4647-a58e-4cb5ecc8876f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cost(params, input_size, hidden_size2, num_labels, X, y_onehot, learning_rate)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.463441953164322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3UgDvN9V-U4",
        "colab_type": "text"
      },
      "source": [
        "## Forward propogation with regularization and Cost\n",
        "\n",
        "Our next step is to add regularization to the cost function.  If you're following along in the exercise text and thought the last equation looked ugly, this one looks REALLY ugly.  It's actually not as complicated as it looks though - in fact, the regularization term is simply an addition to the cost we already computed.  Here's the revised cost function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nmmwxRsV-U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(params, input_size, hidden_size2, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    \n",
        "    n1 = hidden_size2 * (input_size + 1)\n",
        "    n2 = n1 + num_labels * (hidden_size2 + 1)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:n1], (hidden_size2, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[n1:n2], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnUo1RWyV-U8",
        "colab_type": "code",
        "outputId": "61226909-cd9f-4335-826f-37762c148aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cost(params, input_size, hidden_size2, num_labels, X, y_onehot, learning_rate)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.4741574476515416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPO4fBbV-VB",
        "colab_type": "text"
      },
      "source": [
        "Next up is the backpropagation algorithm.  Backpropagation computes the parameter updates that will reduce the error of the network on the training data.  The first thing we need is a function that computes the gradient of the sigmoid function we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsAFEyqLV-VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_gradient(z):\n",
        "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqm8Y8TiV-VG",
        "colab_type": "text"
      },
      "source": [
        "## Backpropogation\n",
        "\n",
        "Now we're ready to implement backpropagation to compute the gradients.  Since the computations required for backpropagation are a superset of those required in the cost function, we're actually going to extend the cost function to also perform backpropagation and return both the cost and the gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zevj9cwYV-VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(params, input_size, hidden_size2, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # initializations\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
        "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
        "    \n",
        "    # compute the cost\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    # perform backpropagation\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]  # (1, 401)\n",
        "        z2t = z2[t,:]  # (1, 25)\n",
        "        a2t = a2[t,:]  # (1, 26)\n",
        "        ht = h[t,:]  # (1, 10)\n",
        "        yt = y[t,:]  # (1, 10)\n",
        "        \n",
        "        d3t = ht - yt  # (1, 10)\n",
        "        \n",
        "        #insert a one in first position for bias\n",
        "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
        "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
        "        \n",
        "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
        "        delta2 = delta2 + d3t.T * a2t\n",
        "        \n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    \n",
        "    # unravel the gradient matrices into a single array\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
        "    \n",
        "    return J, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH6HvA3TV-VK",
        "colab_type": "text"
      },
      "source": [
        "The hardest part of the backprop computation (other than understanding WHY we're doing all these calculations) is getting the matrix dimensions right.  By the way, if you find it confusing when to use A * B vs. np.multiply(A, B), you're not alone.  Basically the former is a matrix multiplication and the latter is an element-wise multiplication (unless A or B is a scalar value, in which case it doesn't matter).  I wish there was a more concise syntax for this (maybe there is and I'm just not aware of it).\n",
        "\n",
        "Anyway, let's test it out to make sure the function returns what we're expecting it to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kYpMQFEV-VK",
        "colab_type": "code",
        "outputId": "453a8b06-51f4-42c4-f7ed-ab06eff8dd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "J, grad = backprop(params, input_size, hidden_size2, num_labels, X, y_onehot, learning_rate)\n",
        "J, grad.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.4741574476515416, (20560,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIWxwggUV-VO",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 4:\n",
        "\n",
        "1.  Split the datasets X_df and y_onehot into 80% for training and the rest for testing using:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "2. Then use only the train datasets to train (in the next cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tatzdOLbsry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain,xTest,yTrain,yTest=train_test_split(X_df,y_onehot,test_size=0.2,random_state=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZNC7qatV-VO",
        "colab_type": "code",
        "outputId": "96f1ea1d-c1a3-4324-8bf7-f2892505f4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# minimize the objective function\n",
        "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size2, num_labels, xTrain, yTrain, learning_rate), \n",
        "                method='TNC', jac=True, options={'maxiter': 250})\n",
        "fmin"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0.6278534508276323\n",
              "     jac: array([-0.00227172,  0.        ,  0.        , ..., -0.001236  ,\n",
              "       -0.00192575, -0.00171405])\n",
              " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
              "    nfev: 166\n",
              "     nit: 13\n",
              "  status: 1\n",
              " success: True\n",
              "       x: array([-0.34742778, -0.00526084, -0.11417281, ..., -2.425162  ,\n",
              "        1.17773217,  1.81111063])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdJdJ7FYV-VS",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 5:\n",
        "\n",
        "1.  Now use only the test datasets to predict (in the next cell\n",
        "2.  And calclate the accuray by comparing to the test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67To5MVVV-VT",
        "colab_type": "code",
        "outputId": "874bd5c2-d081-4514-b4fa-59918d6cd917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = np.matrix(xTest)\n",
        "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(fmin.x[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "y_pred = np.array(np.argmax(h, axis=1))\n",
        "y_pred"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [4],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [5],\n",
              "       [9],\n",
              "       [5],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [7],\n",
              "       [4],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [5],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [5],\n",
              "       [3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [7],\n",
              "       [9],\n",
              "       [2],\n",
              "       [8],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [0],\n",
              "       [4],\n",
              "       [7],\n",
              "       [7],\n",
              "       [5],\n",
              "       [6],\n",
              "       [3],\n",
              "       [3],\n",
              "       [9],\n",
              "       [9],\n",
              "       [2],\n",
              "       [6],\n",
              "       [5],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [0],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [2],\n",
              "       [7],\n",
              "       [6],\n",
              "       [9],\n",
              "       [6],\n",
              "       [4],\n",
              "       [7],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [1],\n",
              "       [5],\n",
              "       [5],\n",
              "       [6],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [9],\n",
              "       [9],\n",
              "       [7],\n",
              "       [9],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [7],\n",
              "       [6],\n",
              "       [1],\n",
              "       [5],\n",
              "       [9],\n",
              "       [1],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [9],\n",
              "       [0],\n",
              "       [6],\n",
              "       [8],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [9],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [8],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [6],\n",
              "       [3],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [6],\n",
              "       [9],\n",
              "       [5],\n",
              "       [1],\n",
              "       [1],\n",
              "       [6],\n",
              "       [9],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [9],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [7],\n",
              "       [6],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [0],\n",
              "       [4],\n",
              "       [4],\n",
              "       [7],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [4],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [6],\n",
              "       [5],\n",
              "       [0],\n",
              "       [6],\n",
              "       [9],\n",
              "       [8],\n",
              "       [0],\n",
              "       [5],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [0],\n",
              "       [7],\n",
              "       [1],\n",
              "       [6],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [3],\n",
              "       [5],\n",
              "       [8],\n",
              "       [9],\n",
              "       [0],\n",
              "       [0],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [6],\n",
              "       [9],\n",
              "       [2],\n",
              "       [1],\n",
              "       [7],\n",
              "       [3],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [6],\n",
              "       [2],\n",
              "       [8],\n",
              "       [7],\n",
              "       [0],\n",
              "       [0],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [7],\n",
              "       [9],\n",
              "       [9],\n",
              "       [5],\n",
              "       [9],\n",
              "       [2],\n",
              "       [5],\n",
              "       [3],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [7],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [2],\n",
              "       [7],\n",
              "       [4],\n",
              "       [9],\n",
              "       [8],\n",
              "       [0],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [5],\n",
              "       [0],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [4],\n",
              "       [9],\n",
              "       [7],\n",
              "       [2],\n",
              "       [4],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [9],\n",
              "       [0],\n",
              "       [0],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [3],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [1],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [1],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [2],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [9],\n",
              "       [2],\n",
              "       [1],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [4],\n",
              "       [5],\n",
              "       [3],\n",
              "       [5],\n",
              "       [4],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [6],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [3],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [3],\n",
              "       [4],\n",
              "       [9],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [7],\n",
              "       [1],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [5],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [6],\n",
              "       [9],\n",
              "       [5],\n",
              "       [7],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [1],\n",
              "       [5],\n",
              "       [6],\n",
              "       [5],\n",
              "       [9],\n",
              "       [5],\n",
              "       [0],\n",
              "       [7],\n",
              "       [1],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [1],\n",
              "       [3],\n",
              "       [5],\n",
              "       [7],\n",
              "       [4],\n",
              "       [9],\n",
              "       [1],\n",
              "       [9],\n",
              "       [6],\n",
              "       [4],\n",
              "       [2],\n",
              "       [7],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [6],\n",
              "       [1],\n",
              "       [9],\n",
              "       [2],\n",
              "       [5],\n",
              "       [5],\n",
              "       [5],\n",
              "       [1],\n",
              "       [7],\n",
              "       [2],\n",
              "       [6],\n",
              "       [6],\n",
              "       [5],\n",
              "       [8],\n",
              "       [0],\n",
              "       [4],\n",
              "       [2],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [1],\n",
              "       [6],\n",
              "       [8],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [0],\n",
              "       [5],\n",
              "       [7],\n",
              "       [7],\n",
              "       [1],\n",
              "       [2],\n",
              "       [6],\n",
              "       [4],\n",
              "       [5],\n",
              "       [8],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [2],\n",
              "       [9],\n",
              "       [1],\n",
              "       [6],\n",
              "       [8],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [0],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [8],\n",
              "       [4],\n",
              "       [8],\n",
              "       [2],\n",
              "       [0],\n",
              "       [5],\n",
              "       [9],\n",
              "       [5],\n",
              "       [1],\n",
              "       [6],\n",
              "       [9],\n",
              "       [1],\n",
              "       [6],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [5],\n",
              "       [6],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [7],\n",
              "       [3],\n",
              "       [3],\n",
              "       [8],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [5],\n",
              "       [6],\n",
              "       [6],\n",
              "       [1],\n",
              "       [9],\n",
              "       [7],\n",
              "       [2],\n",
              "       [4],\n",
              "       [7],\n",
              "       [5],\n",
              "       [4],\n",
              "       [4],\n",
              "       [5],\n",
              "       [1],\n",
              "       [1],\n",
              "       [7],\n",
              "       [7],\n",
              "       [8],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [8],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [6],\n",
              "       [8],\n",
              "       [2],\n",
              "       [2],\n",
              "       [9],\n",
              "       [0],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [2],\n",
              "       [1],\n",
              "       [9],\n",
              "       [1],\n",
              "       [3],\n",
              "       [9],\n",
              "       [6],\n",
              "       [2],\n",
              "       [5],\n",
              "       [1],\n",
              "       [9],\n",
              "       [4],\n",
              "       [3],\n",
              "       [6],\n",
              "       [3],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [5],\n",
              "       [4],\n",
              "       [8],\n",
              "       [4],\n",
              "       [3],\n",
              "       [7],\n",
              "       [9],\n",
              "       [4],\n",
              "       [2],\n",
              "       [0],\n",
              "       [6],\n",
              "       [0],\n",
              "       [9],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [6],\n",
              "       [1],\n",
              "       [4],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [7],\n",
              "       [3],\n",
              "       [7],\n",
              "       [6],\n",
              "       [6],\n",
              "       [3],\n",
              "       [8],\n",
              "       [2],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [6],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [4],\n",
              "       [0],\n",
              "       [2],\n",
              "       [4],\n",
              "       [9],\n",
              "       [3],\n",
              "       [8],\n",
              "       [4],\n",
              "       [9],\n",
              "       [7],\n",
              "       [8],\n",
              "       [6],\n",
              "       [8],\n",
              "       [7],\n",
              "       [0],\n",
              "       [7],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [1],\n",
              "       [2],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [6],\n",
              "       [3],\n",
              "       [5],\n",
              "       [1],\n",
              "       [0],\n",
              "       [6],\n",
              "       [3],\n",
              "       [4],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [2],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [6],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [6],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [9],\n",
              "       [0],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [7],\n",
              "       [1],\n",
              "       [2],\n",
              "       [8],\n",
              "       [9],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [8],\n",
              "       [7],\n",
              "       [4],\n",
              "       [2],\n",
              "       [9],\n",
              "       [0],\n",
              "       [8],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [5],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [9],\n",
              "       [5],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [6],\n",
              "       [5],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [6],\n",
              "       [0],\n",
              "       [9],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [3],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [5],\n",
              "       [4],\n",
              "       [8],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [5],\n",
              "       [4],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [6],\n",
              "       [0],\n",
              "       [5],\n",
              "       [5],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [2],\n",
              "       [5],\n",
              "       [5],\n",
              "       [3],\n",
              "       [1],\n",
              "       [0],\n",
              "       [6],\n",
              "       [5],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [0],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [0],\n",
              "       [2],\n",
              "       [6],\n",
              "       [7],\n",
              "       [0],\n",
              "       [3],\n",
              "       [6],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [7],\n",
              "       [4],\n",
              "       [7],\n",
              "       [9],\n",
              "       [3],\n",
              "       [7],\n",
              "       [0],\n",
              "       [0],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [5],\n",
              "       [3],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [7],\n",
              "       [3],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [3],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [4],\n",
              "       [3],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [5],\n",
              "       [7],\n",
              "       [5],\n",
              "       [7],\n",
              "       [8],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [2],\n",
              "       [0],\n",
              "       [1],\n",
              "       [9],\n",
              "       [5],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [6],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [3],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [4],\n",
              "       [6],\n",
              "       [0],\n",
              "       [4],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [0],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [4],\n",
              "       [0],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [6],\n",
              "       [4],\n",
              "       [3],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [1],\n",
              "       [4],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [6],\n",
              "       [6],\n",
              "       [6],\n",
              "       [8],\n",
              "       [1],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [2],\n",
              "       [6],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [5],\n",
              "       [7],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [9],\n",
              "       [3],\n",
              "       [0],\n",
              "       [9],\n",
              "       [6],\n",
              "       [5],\n",
              "       [4],\n",
              "       [8],\n",
              "       [8],\n",
              "       [1],\n",
              "       [5],\n",
              "       [5],\n",
              "       [2],\n",
              "       [0],\n",
              "       [9],\n",
              "       [3],\n",
              "       [0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [5],\n",
              "       [5],\n",
              "       [4],\n",
              "       [1],\n",
              "       [0],\n",
              "       [8],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [3],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [5],\n",
              "       [5],\n",
              "       [2],\n",
              "       [2],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [1],\n",
              "       [6],\n",
              "       [6],\n",
              "       [9],\n",
              "       [5],\n",
              "       [4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FHgFFfrV-VX",
        "colab_type": "code",
        "outputId": "4a342e2c-4d33-4074-84db-a0a7a652b7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [9],\n",
              "        [9],\n",
              "        [9]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_orukeV-Vd",
        "colab_type": "text"
      },
      "source": [
        "Finally we can compute the accuracy to see how well our trained network is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTPHLdaiV-Vf",
        "colab_type": "code",
        "outputId": "246dd0d8-3772-47d7-9d09-004ad98d88dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
        "accuracy = sum(correct)/len(correct)\n",
        "print('accuracy = {0}%'.format(accuracy * 1000))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 95.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwjbskARV-Vk",
        "colab_type": "text"
      },
      "source": [
        "### Optional exercise: complete the same train and test parts for the regualrized version of the model below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc44Jc0eV-Vm",
        "colab_type": "text"
      },
      "source": [
        "### Regularization:\n",
        "\n",
        "We still have one more modification to make to the backprop function - adding regularization to the gradient calculations.  The final regularized version is below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS-fldtIV-Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(params, input_size, hidden_size2, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # initializations\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
        "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
        "    \n",
        "    # compute the cost\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    # perform backpropagation\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]  # (1, 401)\n",
        "        z2t = z2[t,:]  # (1, 25)\n",
        "        a2t = a2[t,:]  # (1, 26)\n",
        "        ht = h[t,:]  # (1, 10)\n",
        "        yt = y[t,:]  # (1, 10)\n",
        "        \n",
        "        d3t = ht - yt  # (1, 10)\n",
        "        \n",
        "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
        "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
        "        \n",
        "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
        "        delta2 = delta2 + d3t.T * a2t\n",
        "        \n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    \n",
        "    # add the gradient regularization term\n",
        "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
        "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
        "    \n",
        "    # unravel the gradient matrices into a single array\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
        "    \n",
        "    return J, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Au4fuXV-Vs",
        "colab_type": "code",
        "outputId": "8d223bdb-777f-4c00-d21f-983383a271a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "J, grad = backprop(params, input_size, hidden_size2, num_labels, X, y_onehot, learning_rate)\n",
        "J, grad.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.644387160574972, (20560,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToMM6FO8V-Vw",
        "colab_type": "text"
      },
      "source": [
        "We're finally ready to train our network and use it to make predictions.  This is roughly similar to the previous exercise with multi-class logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHuurw-UV-Vw",
        "colab_type": "code",
        "outputId": "e4cb59e1-a025-4ede-d55d-6604352632ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# minimize the objective function\n",
        "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size2, num_labels, xTest, yTest, learning_rate), \n",
        "                method='TNC', jac=True, options={'maxiter': 250})\n",
        "fmin"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0.5513944138191929\n",
              "     jac: array([-4.55638820e-04,  1.20542599e-08,  1.17770732e-06, ...,\n",
              "        1.39081054e-04,  3.18096864e-04,  3.22467532e-04])\n",
              " message: 'Max. number of function evaluations reached'\n",
              "    nfev: 250\n",
              "     nit: 21\n",
              "  status: 3\n",
              " success: False\n",
              "       x: array([-9.49888741e-01,  1.20542599e-05,  1.17770732e-03, ...,\n",
              "       -1.22613733e+00,  8.58022265e-02,  1.30339577e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnEieidV-V0",
        "colab_type": "text"
      },
      "source": [
        "We put a bound on the number of iterations since the objective function is not likely to completely converge.  Our total cost has dropped below 0.5 though so that's a good indicator that the algorithm is working.  Let's use the parameters it found and forward-propagate them through the network to get some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44kXvP9oV-V0",
        "colab_type": "code",
        "outputId": "b76c5e54-2bf7-4f50-b6f0-274d72b888cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = np.matrix(X)\n",
        "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(fmin.x[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "y_pred = np.array(np.argmax(h, axis=1))\n",
        "y_pred"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [4],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [5],\n",
              "       [9],\n",
              "       [5],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [2],\n",
              "       [0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [5],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [7],\n",
              "       [6],\n",
              "       [3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [7],\n",
              "       [9],\n",
              "       [2],\n",
              "       [6],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [0],\n",
              "       [4],\n",
              "       [7],\n",
              "       [7],\n",
              "       [5],\n",
              "       [6],\n",
              "       [3],\n",
              "       [3],\n",
              "       [9],\n",
              "       [9],\n",
              "       [2],\n",
              "       [6],\n",
              "       [5],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [0],\n",
              "       [5],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [7],\n",
              "       [6],\n",
              "       [9],\n",
              "       [6],\n",
              "       [4],\n",
              "       [7],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [1],\n",
              "       [5],\n",
              "       [5],\n",
              "       [6],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [9],\n",
              "       [1],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [4],\n",
              "       [9],\n",
              "       [7],\n",
              "       [9],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [7],\n",
              "       [6],\n",
              "       [1],\n",
              "       [5],\n",
              "       [9],\n",
              "       [1],\n",
              "       [4],\n",
              "       [2],\n",
              "       [0],\n",
              "       [9],\n",
              "       [0],\n",
              "       [6],\n",
              "       [8],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [7],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [8],\n",
              "       [7],\n",
              "       [2],\n",
              "       [2],\n",
              "       [6],\n",
              "       [3],\n",
              "       [5],\n",
              "       [1],\n",
              "       [5],\n",
              "       [6],\n",
              "       [9],\n",
              "       [5],\n",
              "       [1],\n",
              "       [1],\n",
              "       [6],\n",
              "       [9],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [0],\n",
              "       [0],\n",
              "       [5],\n",
              "       [0],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [1],\n",
              "       [7],\n",
              "       [6],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [0],\n",
              "       [4],\n",
              "       [4],\n",
              "       [7],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [4],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [6],\n",
              "       [5],\n",
              "       [0],\n",
              "       [6],\n",
              "       [3],\n",
              "       [8],\n",
              "       [0],\n",
              "       [5],\n",
              "       [5],\n",
              "       [3],\n",
              "       [8],\n",
              "       [5],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [0],\n",
              "       [9],\n",
              "       [1],\n",
              "       [6],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [3],\n",
              "       [5],\n",
              "       [6],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [6],\n",
              "       [9],\n",
              "       [2],\n",
              "       [7],\n",
              "       [7],\n",
              "       [3],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [6],\n",
              "       [2],\n",
              "       [8],\n",
              "       [7],\n",
              "       [0],\n",
              "       [0],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [7],\n",
              "       [9],\n",
              "       [9],\n",
              "       [5],\n",
              "       [9],\n",
              "       [2],\n",
              "       [5],\n",
              "       [3],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [7],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [0],\n",
              "       [8],\n",
              "       [0],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [5],\n",
              "       [0],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [4],\n",
              "       [9],\n",
              "       [7],\n",
              "       [2],\n",
              "       [4],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [9],\n",
              "       [7],\n",
              "       [0],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [3],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [1],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [1],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [2],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [9],\n",
              "       [2],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [5],\n",
              "       [3],\n",
              "       [5],\n",
              "       [4],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [8],\n",
              "       [6],\n",
              "       [7],\n",
              "       [6],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [3],\n",
              "       [1],\n",
              "       [6],\n",
              "       [7],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [3],\n",
              "       [5],\n",
              "       [7],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [7],\n",
              "       [9],\n",
              "       [0],\n",
              "       [5],\n",
              "       [0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [5],\n",
              "       [3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [7],\n",
              "       [7],\n",
              "       [6],\n",
              "       [0],\n",
              "       [1],\n",
              "       [5],\n",
              "       [6],\n",
              "       [5],\n",
              "       [9],\n",
              "       [5],\n",
              "       [0],\n",
              "       [7],\n",
              "       [1],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [1],\n",
              "       [5],\n",
              "       [5],\n",
              "       [7],\n",
              "       [4],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [6],\n",
              "       [4],\n",
              "       [2],\n",
              "       [7],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [6],\n",
              "       [1],\n",
              "       [9],\n",
              "       [2],\n",
              "       [5],\n",
              "       [5],\n",
              "       [5],\n",
              "       [1],\n",
              "       [7],\n",
              "       [2],\n",
              "       [6],\n",
              "       [6],\n",
              "       [5],\n",
              "       [8],\n",
              "       [0],\n",
              "       [4],\n",
              "       [2],\n",
              "       [8],\n",
              "       [4],\n",
              "       [4],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [9],\n",
              "       [8],\n",
              "       [1],\n",
              "       [6],\n",
              "       [8],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [0],\n",
              "       [5],\n",
              "       [7],\n",
              "       [7],\n",
              "       [1],\n",
              "       [2],\n",
              "       [6],\n",
              "       [4],\n",
              "       [5],\n",
              "       [8],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [7],\n",
              "       [9],\n",
              "       [2],\n",
              "       [6],\n",
              "       [8],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [0],\n",
              "       [2],\n",
              "       [9],\n",
              "       [9],\n",
              "       [6],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [5],\n",
              "       [9],\n",
              "       [2],\n",
              "       [1],\n",
              "       [6],\n",
              "       [9],\n",
              "       [1],\n",
              "       [6],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [8],\n",
              "       [6],\n",
              "       [5],\n",
              "       [2],\n",
              "       [0],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [7],\n",
              "       [5],\n",
              "       [2],\n",
              "       [8],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [6],\n",
              "       [6],\n",
              "       [1],\n",
              "       [9],\n",
              "       [7],\n",
              "       [2],\n",
              "       [4],\n",
              "       [7],\n",
              "       [5],\n",
              "       [4],\n",
              "       [4],\n",
              "       [5],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [7],\n",
              "       [8],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [8],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [4],\n",
              "       [6],\n",
              "       [6],\n",
              "       [8],\n",
              "       [6],\n",
              "       [8],\n",
              "       [2],\n",
              "       [2],\n",
              "       [9],\n",
              "       [0],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [2],\n",
              "       [1],\n",
              "       [9],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [6],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [9],\n",
              "       [4],\n",
              "       [3],\n",
              "       [6],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [6],\n",
              "       [4],\n",
              "       [8],\n",
              "       [4],\n",
              "       [3],\n",
              "       [7],\n",
              "       [9],\n",
              "       [4],\n",
              "       [2],\n",
              "       [0],\n",
              "       [6],\n",
              "       [0],\n",
              "       [9],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [6],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [8],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [6],\n",
              "       [6],\n",
              "       [3],\n",
              "       [8],\n",
              "       [2],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [6],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [4],\n",
              "       [0],\n",
              "       [2],\n",
              "       [4],\n",
              "       [9],\n",
              "       [3],\n",
              "       [8],\n",
              "       [4],\n",
              "       [9],\n",
              "       [7],\n",
              "       [8],\n",
              "       [6],\n",
              "       [9],\n",
              "       [7],\n",
              "       [0],\n",
              "       [7],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [1],\n",
              "       [2],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [6],\n",
              "       [8],\n",
              "       [5],\n",
              "       [1],\n",
              "       [0],\n",
              "       [6],\n",
              "       [3],\n",
              "       [4],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [2],\n",
              "       [4],\n",
              "       [6],\n",
              "       [4],\n",
              "       [6],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [6],\n",
              "       [2],\n",
              "       [5],\n",
              "       [9],\n",
              "       [9],\n",
              "       [0],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [7],\n",
              "       [1],\n",
              "       [2],\n",
              "       [8],\n",
              "       [9],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [8],\n",
              "       [7],\n",
              "       [4],\n",
              "       [2],\n",
              "       [9],\n",
              "       [0],\n",
              "       [8],\n",
              "       [0],\n",
              "       [3],\n",
              "       [0],\n",
              "       [5],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [9],\n",
              "       [5],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [8],\n",
              "       [5],\n",
              "       [6],\n",
              "       [5],\n",
              "       [7],\n",
              "       [7],\n",
              "       [2],\n",
              "       [6],\n",
              "       [0],\n",
              "       [9],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [8],\n",
              "       [1],\n",
              "       [7],\n",
              "       [1],\n",
              "       [9],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [3],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [5],\n",
              "       [4],\n",
              "       [8],\n",
              "       [9],\n",
              "       [7],\n",
              "       [6],\n",
              "       [5],\n",
              "       [4],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [5],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [1],\n",
              "       [7],\n",
              "       [4],\n",
              "       [2],\n",
              "       [0],\n",
              "       [5],\n",
              "       [8],\n",
              "       [1],\n",
              "       [0],\n",
              "       [6],\n",
              "       [5],\n",
              "       [5],\n",
              "       [9],\n",
              "       [8],\n",
              "       [8],\n",
              "       [2],\n",
              "       [0],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [0],\n",
              "       [2],\n",
              "       [6],\n",
              "       [7],\n",
              "       [0],\n",
              "       [5],\n",
              "       [6],\n",
              "       [7],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [7],\n",
              "       [4],\n",
              "       [7],\n",
              "       [9],\n",
              "       [3],\n",
              "       [7],\n",
              "       [0],\n",
              "       [0],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [9],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [7],\n",
              "       [3],\n",
              "       [0],\n",
              "       [7],\n",
              "       [6],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [4],\n",
              "       [3],\n",
              "       [3],\n",
              "       [7],\n",
              "       [4],\n",
              "       [3],\n",
              "       [7],\n",
              "       [5],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [4],\n",
              "       [6],\n",
              "       [2],\n",
              "       [0],\n",
              "       [1],\n",
              "       [9],\n",
              "       [5],\n",
              "       [3],\n",
              "       [6],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [9],\n",
              "       [5],\n",
              "       [6],\n",
              "       [0],\n",
              "       [8],\n",
              "       [8],\n",
              "       [3],\n",
              "       [6],\n",
              "       [7],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [6],\n",
              "       [9],\n",
              "       [3],\n",
              "       [1],\n",
              "       [8],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [4],\n",
              "       [6],\n",
              "       [0],\n",
              "       [4],\n",
              "       [9],\n",
              "       [8],\n",
              "       [3],\n",
              "       [0],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [0],\n",
              "       [4],\n",
              "       [1],\n",
              "       [8],\n",
              "       [8],\n",
              "       [5],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [9],\n",
              "       [9],\n",
              "       [3],\n",
              "       [3],\n",
              "       [6],\n",
              "       [4],\n",
              "       [3],\n",
              "       [0],\n",
              "       [2],\n",
              "       [8],\n",
              "       [1],\n",
              "       [4],\n",
              "       [5],\n",
              "       [1],\n",
              "       [8],\n",
              "       [9],\n",
              "       [6],\n",
              "       [6],\n",
              "       [6],\n",
              "       [8],\n",
              "       [6],\n",
              "       [6],\n",
              "       [6],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [6],\n",
              "       [6],\n",
              "       [2],\n",
              "       [5],\n",
              "       [7],\n",
              "       [8],\n",
              "       [8],\n",
              "       [8],\n",
              "       [9],\n",
              "       [3],\n",
              "       [0],\n",
              "       [9],\n",
              "       [5],\n",
              "       [5],\n",
              "       [4],\n",
              "       [8],\n",
              "       [3],\n",
              "       [1],\n",
              "       [5],\n",
              "       [5],\n",
              "       [2],\n",
              "       [7],\n",
              "       [9],\n",
              "       [3],\n",
              "       [0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [5],\n",
              "       [5],\n",
              "       [4],\n",
              "       [1],\n",
              "       [0],\n",
              "       [8],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [2],\n",
              "       [9],\n",
              "       [3],\n",
              "       [6],\n",
              "       [6],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [6],\n",
              "       [5],\n",
              "       [2],\n",
              "       [2],\n",
              "       [6],\n",
              "       [2],\n",
              "       [7],\n",
              "       [5],\n",
              "       [6],\n",
              "       [6],\n",
              "       [9],\n",
              "       [8],\n",
              "       [4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhCp_r-HV-V3",
        "colab_type": "text"
      },
      "source": [
        "Finally we can compute the accuracy to see how well our trained network is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL-xGc724qQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = np.argmax(yTest,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM58RkbJV-V4",
        "colab_type": "code",
        "outputId": "3d8e247b-5017-4970-f04d-050285b6b4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y_new)]\n",
        "accuracy = sum(correct)/len(correct)\n",
        "print('accuracy = {0}%'.format(accuracy * 100))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 99.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihO5Ht0TV-V7",
        "colab_type": "text"
      },
      "source": [
        "And we're done!  We've successfully implemented a rudimentary feed-forward neural network with backpropagation and used it to classify images of handwritten digits.  In the next exercise we'll look at another power supervised learning algorithm, support vector machines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-evb9XbmV-V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}